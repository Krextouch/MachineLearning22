{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prüfungsleitung Maschnielles Lernen: Gruppe 8\n",
    "\n",
    "Isolet download: https://datahub.io/machine-learning/isolet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import isolet.csv File\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "df_raw_isolet = pd.read_csv(\"./raw_isolet.csv\", delimiter=\",\")\n",
    "\n",
    "# changing column name 'class' to 'letter' 'cause class is a reservated keyword in python \n",
    "df_raw_isolet.rename(columns={'class': 'letter'}, inplace=True)\n",
    "# removing char ' from letter\n",
    "df_raw_isolet['letter'] = df_raw_isolet['letter'].replace({'\\'': ''}, regex=True)\n",
    "\n",
    "df_raw_isolet_subset = df_raw_isolet.iloc[:2000]\n",
    "\n",
    "X_subset = df_raw_isolet_subset.iloc[:, :617]\n",
    "y_subset = df_raw_isolet_subset.iloc[:, 617]\n",
    "\n",
    "X = df_raw_isolet.iloc[:, :617]\n",
    "y = df_raw_isolet.iloc[:, 617]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Einfache Datenbetrachtung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einträge in isolet.csv 7797\n",
      "Gruppierte Einträge: letter\n",
      "1     300\n",
      "10    300\n",
      "11    300\n",
      "12    300\n",
      "13    299\n",
      "14    300\n",
      "15    300\n",
      "16    300\n",
      "17    300\n",
      "18    300\n",
      "19    300\n",
      "2     300\n",
      "20    300\n",
      "21    300\n",
      "22    300\n",
      "23    300\n",
      "24    300\n",
      "25    300\n",
      "26    300\n",
      "3     300\n",
      "4     300\n",
      "5     300\n",
      "6     298\n",
      "7     300\n",
      "8     300\n",
      "9     300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Einträge in isolet.csv\", len(df_raw_isolet))\n",
    "print(\"Gruppierte Einträge:\", df_raw_isolet.groupby(['letter']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Betrachtung der Anzahl ist aufällig, dass in der Regel pro Buchstabe 300 Einträge aufgezeichnet wurden. Da aber len(df) nur 7797 Einträge beinhaltet, gibt es einige Ausnahmen. <br>\n",
    "Ausnahmen: Buchstabe 13 mit 299 Einträgen und Buchstabe 6 mit 298 Einträgen <br><br>\n",
    "Insgesamt bietet die sehr ausgewogene Verteilung der jeweiligen Buchstaben eine sehr gute Basis dies in dem Data Splitting zu betrachten. So wird für jeden Buchstaben ein Testsatz von je 75 Einträge bestimmt. Formel: ⎡Anzahl Einträge pro Buchstabe * 0,25⎤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_raw_isolet: 7797\n",
      "Number of rows in df_training: 5847\n",
      "Number of rows in df_test 1950\n",
      "OK: Check passed!\n"
     ]
    }
   ],
   "source": [
    "df_training = df_raw_isolet.copy()\n",
    "df_test = pd.DataFrame(data=None, columns=df_raw_isolet.columns)\n",
    "numberOfTestEntries = 75\n",
    "\n",
    "for i in range(26):\n",
    "    df_test = pd.concat([df_test, df_training[df_training.letter.str.match(\"^\" + str(i+1) + \"$\")].head(numberOfTestEntries)])\n",
    "df_training.drop(df_test.index, inplace=True)\n",
    "\n",
    "# check\n",
    "print(\"Number of rows in df_raw_isolet:\", len(df_raw_isolet))\n",
    "print(\"Number of rows in df_training:\", len(df_training))\n",
    "print(\"Number of rows in df_test\", len(df_test))\n",
    "if len(df_training) + len(df_test) == len(df_raw_isolet):\n",
    "    print(\"OK: Check passed!\")\n",
    "else: \n",
    "    print(\"WARNING: The number of lines do not match! Diffrence:\", len(df_training) + len(df_test) - len(df_raw_isolet))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=.25, shuffle=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, random_state=42, test_size=.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap can not be pushed to git. calculate it on your local machine\n",
    "\n",
    "# plt.figure(figsize=(150, 100))\n",
    "# fig = sns.heatmap(X_train.corr(), annot=True, cmap=sns.cm.rocket_r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merkmalstransformation - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merkmalsselektion - Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([199, 198, 200, 222, 201, 145, 512, 513, 481, 223, 482, 545, 221,\n",
       "       511, 514,  33, 228, 480, 543, 544, 155, 227, 450, 546, 510, 322,\n",
       "       229, 202, 479, 577, 321, 542, 449, 509, 451, 578, 483, 478, 576,\n",
       "       224, 156, 575, 320, 226, 609, 607, 157, 515, 158, 508, 401, 608,\n",
       "       159, 160, 164, 161, 402, 162, 163, 225, 203, 319, 448, 477, 541,\n",
       "       442,  69, 547, 443, 610,  68, 444, 445, 507, 418, 441, 476, 433,\n",
       "       102, 323, 474, 447, 579, 432, 101, 446, 146, 411, 606, 475, 400,\n",
       "       574,  67, 611, 431, 412, 540, 506, 318, 434, 473, 413, 100, 419,\n",
       "       417, 352, 220, 351, 399, 230, 410, 354, 353, 430, 440, 416, 539,\n",
       "       403, 505,  99, 605, 386, 409,  70, 573, 383, 350, 355, 384, 317,\n",
       "       133, 538, 191, 387, 537, 204, 385, 463, 414, 315, 314, 464, 147,\n",
       "       465, 316, 462, 472, 205, 132, 572, 232, 398, 382, 313, 415, 233,\n",
       "       255, 134, 536, 429, 439, 206, 570, 569, 504, 231, 131, 571, 604,\n",
       "       148, 169, 435,  66,  26,  98, 466, 568, 192,  27, 103, 234, 349,\n",
       "       256, 149, 495, 168, 304,  38, 127, 461, 305, 303, 408, 593, 126,\n",
       "       471, 594, 438, 150,  94,  71, 496, 497, 130, 404,  95, 599, 567,\n",
       "       170, 600, 151, 595, 397, 306, 535, 125, 312, 603, 494, 104, 143,\n",
       "        96, 136, 601, 152, 598, 197, 592,  28, 207, 235,  97, 302, 128,\n",
       "       381, 597, 153, 503, 124, 154,  93, 596,  62,  25,  63, 190, 602,\n",
       "       196, 436, 257, 428, 254,  73,  76, 137, 498, 452, 437,  61,  92,\n",
       "       527, 129, 123,  77, 561,  19, 484, 566, 560, 528, 405,  72, 407,\n",
       "        78,  75, 529, 470, 195,  79,  74,  64, 591,  32, 122,  65, 467,\n",
       "        80, 559,  91, 460, 493,  20, 526,  36, 175,  90, 135, 562, 406,\n",
       "       194,  41, 343,  47,  29, 167, 193,  60, 301, 344, 109, 486,  44,\n",
       "       311, 307,   0, 181, 258,  46, 420, 530, 348, 516, 396, 121,  45,\n",
       "        30, 260, 534, 292, 108,  24,  43,  89, 105, 342, 375, 454, 558,\n",
       "        57,   1,   2, 111, 563, 324, 110,  59, 236,  81, 380,  48, 107,\n",
       "       359,  42, 502, 259, 427, 590, 469, 499, 291, 293, 341, 374, 525,\n",
       "       340,  58, 345, 106, 565, 468, 564, 337, 290, 612, 358, 112, 376,\n",
       "       391,   3,  88, 339,  18,  31, 492, 548, 338, 531, 120, 580,   6,\n",
       "       557, 336, 347, 390, 261, 459,   4,  82, 589,   5, 208, 188, 518,\n",
       "       485,  49,  56, 310, 370, 346, 369, 165, 388, 517, 335, 373, 533,\n",
       "        21, 426, 377, 392, 166, 585, 174, 300,   7, 500, 371, 588, 326,\n",
       "       379, 586, 524,  50, 308, 587, 138, 615, 176, 113, 501, 285, 356,\n",
       "       184, 372,  51, 289,  37,  87,  40, 614, 252,  83, 367,  55, 556,\n",
       "       139, 532, 334, 245, 140, 395, 309,  35, 368, 455, 177, 458, 360,\n",
       "       237, 284, 180, 119, 425, 357, 366, 244, 491, 378, 487, 453, 171,\n",
       "       114, 294, 550, 553, 182,  84, 264, 613,  86,  52, 183, 457, 246,\n",
       "       118, 549,  23, 333, 394, 523, 209, 262,  54, 332, 554,  85, 299,\n",
       "       555,   8,  39, 280, 365, 115, 251, 238, 210, 423, 185, 283, 253,\n",
       "       393, 279, 331, 490, 325, 422, 141, 330, 389,  53, 187, 281, 327,\n",
       "       364, 522, 117, 521, 189, 282, 265, 329, 211, 278, 489,  22, 116,\n",
       "       582, 363, 298, 288, 583, 519, 362, 213, 361, 266,   9,  17, 297,\n",
       "       616, 551, 295, 277, 219, 456, 214, 243, 488, 212, 142, 581, 172,\n",
       "       178,  14, 263,  16, 215, 239,  15, 247, 276, 267, 173, 424, 421,\n",
       "       250, 296, 218, 217,  10, 216, 275, 328, 240, 249,  13, 520,  12,\n",
       "       241, 268, 274, 287, 584,  11, 242, 286,  34, 248, 552, 186, 269,\n",
       "       179, 144, 273, 270, 272, 271])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "\n",
    "rank_idx = fisher_score.fisher_score(X_train, y_train, mode='rank')\n",
    "rank_idx\n",
    "\n",
    "# n_samples, n_features = np.shape(X_train)\n",
    "\n",
    "# print(n_samples, n_features)\n",
    "\n",
    "# # print(np.shape(X_train))\n",
    "# print(np.shape(y_train))\n",
    "# X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.381  -0.4842 -0.639  ...  0.1694  0.114  -0.9714]\n",
      " [-0.4308 -0.4414 -0.4628 ...  0.5732  0.4666 -1.    ]\n",
      " [-0.4552 -0.5484 -0.8028 ...  0.7552  0.6666 -0.9142]\n",
      " ...\n",
      " [ 0.4374  0.5838  0.133  ...  0.5468  0.5834 -0.6572]\n",
      " [-0.4526 -0.2548 -0.2884 ...  0.0748  0.1956 -1.    ]\n",
      " [-0.088  -0.3368 -0.1244 ...  0.803   0.34   -1.    ]]\n"
     ]
    }
   ],
   "source": [
    "num_features = 100\n",
    "selected_features_train = X_subset[:, rank_idx[:num_features]]\n",
    "selected_features_test = X_test[:, rank_idx[:num_features]]\n",
    "\n",
    "print(selected_features_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 25 20 ... 15 12 12]\n",
      "[[-0.4086649   0.09462252  0.40381854 ...  0.16115894  0.05166093\n",
      "  -0.3559404 ]\n",
      " [-0.3159136   0.22703867  0.42915227 ...  0.13672508  0.04475287\n",
      "  -0.32242719]\n",
      " [-0.518315   -0.05362111  0.10804944 ...  0.72556611  0.63081444\n",
      "   0.29487667]\n",
      " ...\n",
      " [-0.24440303  0.28253636  0.58490909 ...  0.19349242  0.03912273\n",
      "  -0.34466061]\n",
      " [-0.08386934  0.47734745  0.46792847 ...  0.18338613  0.0646854\n",
      "  -0.36468248]\n",
      " [-0.46768812  0.03074554  0.25454752 ...  0.09820693 -0.00815149\n",
      "  -0.34132871]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=26, random_state=42).fit(X.to_numpy())\n",
    "print(kmeans.labels_)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "score = cross_val_score(RandomForestClassifier(), X_train, y_train, cv=3)\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RandomForestClassifier(), selected_features_train, y_train, cv=3)\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(RandomForestClassifier(), pca.transform(X_train), y_train, cv=3)\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.878, 0.936, 0.942]),\n",
       " array([0.792, 0.81 , 0.874]),\n",
       " array([0.86 , 0.896, 0.912])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Implementierung der Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
