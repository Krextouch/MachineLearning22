{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prüfungsleitung Maschnielles Lernen: Gruppe 8\n",
    "\n",
    "Isolet download: https://datahub.io/machine-learning/isolet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Data Loading and Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import isolet.csv File\n",
    "import pandas as pd\n",
    "\n",
    "# import\n",
    "df_raw_isolet = pd.read_csv(\"./raw_isolet.csv\", delimiter=\",\")\n",
    "\n",
    "# changing column name 'class' to 'letter' 'cause class is a reservated keyword in python \n",
    "df_raw_isolet.rename(columns={'class': 'letter'}, inplace=True)\n",
    "# removing char ' from letter\n",
    "def removeApostrophes(value):\n",
    "    if isinstance(value, str) and str(value).startswith('\\'') and str(value).endswith('\\''):\n",
    "        return str(value).replace('\\'', '')\n",
    "\n",
    "df_raw_isolet.loc[:, 'letter'] = df_raw_isolet.letter.apply(lambda x: removeApostrophes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Einfache Datenbetrachtung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einträge in isolet.csv 7797\n",
      "Gruppierte Einträge: letter\n",
      "1     300\n",
      "10    300\n",
      "11    300\n",
      "12    300\n",
      "13    299\n",
      "14    300\n",
      "15    300\n",
      "16    300\n",
      "17    300\n",
      "18    300\n",
      "19    300\n",
      "2     300\n",
      "20    300\n",
      "21    300\n",
      "22    300\n",
      "23    300\n",
      "24    300\n",
      "25    300\n",
      "26    300\n",
      "3     300\n",
      "4     300\n",
      "5     300\n",
      "6     298\n",
      "7     300\n",
      "8     300\n",
      "9     300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Einträge in isolet.csv\", len(df_raw_isolet))\n",
    "print(\"Gruppierte Einträge:\", df_raw_isolet.groupby(['letter']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Betrachtung der Anzahl ist aufällig, dass in der Regel pro Buchstabe 300 Einträge aufgezeichnet wurden. Da aber len(df) nur 7797 Einträge beinhaltet, gibt es einige Ausnahmen. <br>\n",
    "Ausnahmen: Buchstabe 13 mit 299 Einträgen und Buchstabe 6 mit 298 Einträgen <br><br>\n",
    "Insgesamt bietet die sehr ausgewogene Verteilung der jeweiligen Buchstaben eine sehr gute Basis dies in dem Data Splitting zu betrachten. So wird für jeden Buchstaben ein Testsatz von je 75 Einträhge bestimmt. Formel: ⎡Anzahl Einträge pro Buchstabe * 0,25⎤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kev\\AppData\\Local\\Temp\\ipykernel_19804\\503049006.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_splitting_training[letterIndex].drop(index=df_splitting_training[letterIndex].index[:numberOfTestEntries], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_splitting_training = []\n",
    "df_splitting_test = []\n",
    "numberOfTestEntries = 75\n",
    "\n",
    "i = 0\n",
    "for i in range(26):\n",
    "    df_splitting_training.append(df_raw_isolet[df_raw_isolet.letter.str.match(\"^\" + str(i+1) + \"$\")])\n",
    "\n",
    "# test case that each enry has a max of 300 entries\n",
    "for letterIndex, df in enumerate(df_splitting_training):\n",
    "    if len(df_splitting_training[letterIndex]) > 300:\n",
    "        print(\"WARNING: df_splitting[\" + str(letterIndex) + \"] has more than 300 entries!\")\n",
    "\n",
    "# split into test and training sets \n",
    "for letterIndex, df in enumerate(df_splitting_training):\n",
    "    df_splitting_test.append(df_splitting_training[letterIndex].head(numberOfTestEntries))\n",
    "    df_splitting_training[letterIndex].drop(index=df_splitting_training[letterIndex].index[:numberOfTestEntries], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Merkmalsreduktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Implementierung der Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dd69eae55e705b2da1b21fed397856b7f9232722f93735536e7e30961eea810"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
